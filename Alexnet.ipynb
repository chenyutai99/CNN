{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, padding=2, stride=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=256*6*6, out_features=4096)\n",
    "        self.fc2 = nn.Linear(in_features=4096, out_features=1024)\n",
    "        self.fc3 = nn.Linear(in_features=1024, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 128\n",
    "num_epochs = 30\n",
    "lr = 0.001\n",
    "\n",
    "num_classes=2\n",
    "model = AlexNet(num_classes)\n",
    "\n",
    "if CUDA:\n",
    "    model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# kaggle api\n",
    "api_token = {\"username\":\"aaa\",\"key\":\"kkk\"}\n",
    " \n",
    "if not os.path.exists(\"/root/.kaggle\"):\n",
    "    os.makedirs(\"/root/.kaggle\")\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    " \n",
    "if not os.path.exists(\"/kaggle\"):\n",
    "    os.makedirs(\"/kaggle\")\n",
    "os.chdir('/kaggle')\n",
    "!kaggle datasets download -d chetankv/dogs-cats-images --force\n",
    " \n",
    "!ls /kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip dogs-cats-images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "transform = transforms.Compose(\n",
    "                [transforms.Resize(size=(227,227)),\n",
    "                 transforms.CenterCrop(224),\n",
    "                 transforms.RandomRotation(20),\n",
    "                  transforms.RandomHorizontalFlip(),\n",
    "                 transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),]\n",
    "                )\n",
    "\n",
    "# Data\n",
    "train_dataset = datasets.ImageFolder(root='/kaggle/dataset/training_set', transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(root='/kaggle/dataset/test_set', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target) \n",
    "        \n",
    "        if CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        # clear gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagation\n",
    "        output = model(data) \n",
    "        loss = criterion(output, target) \n",
    "\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        total_train += len(target)\n",
    "        correct_train += sum((predicted == target).float())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\"Train Epoch: {}/{} [iter： {}/{}], acc： {:.6f}, loss： {:.6f}\".format(\n",
    "               epoch+1, num_epochs, batch_idx+1, len(train_loader),\n",
    "               correct_train / float((batch_idx + 1) * batch_size),\n",
    "               train_loss / float((batch_idx + 1) * batch_size)))\n",
    "            \n",
    "    train_acc_ = 100 * (correct_train / float(total_train))\n",
    "    train_loss_ = train_loss / total_train\n",
    "                    \n",
    "    return train_acc_, train_loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_loader, model, criterion, epoch): \n",
    "    model.eval()\n",
    "    total_valid = 0\n",
    "    correct_valid = 0\n",
    "    valid_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        data, target = Variable(data), Variable(target) \n",
    "        \n",
    "        if CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target) \n",
    "\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        total_valid += len(target)\n",
    "        correct_valid += sum((predicted == target).float())\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\"Valid Epoch: {}/{} [iter： {}/{}], acc： {:.6f}, loss： {:.6f}\".format(\n",
    "               epoch+1, num_epochs, batch_idx+1, len(valid_loader),\n",
    "               correct_valid / float((batch_idx + 1) * batch_size),\n",
    "               valid_loss / float((batch_idx + 1) * batch_size)))\n",
    "            \n",
    "    valid_acc_ = 100 * (correct_valid / float(total_valid))\n",
    "    valid_loss_ = valid_loss / total_valid\n",
    "                    \n",
    "    return valid_acc_, valid_loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader):\n",
    "    # set objects for storing metrics\n",
    "    total_train_loss = []\n",
    "    total_valid_loss = []\n",
    "    total_train_accuracy = []\n",
    "    total_valid_accuracy = []\n",
    " \n",
    "    # Train model\n",
    "    for epoch in range(num_epochs):\n",
    "        # training\n",
    "        train_acc_, train_loss_ = train(train_loader, model, criterion, optimizer, epoch)\n",
    "        total_train_loss.append(train_loss_)\n",
    "        total_train_accuracy.append(train_acc_)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            valid_acc_, valid_loss_ = validate(valid_loader, model, criterion, epoch)\n",
    "            total_valid_loss.append(valid_loss_)\n",
    "            total_valid_accuracy.append(valid_acc_)\n",
    "\n",
    "        print('==========================================================================')\n",
    "        print(\"Epoch: {}/{}， Train acc： {:.6f}， Train loss： {:.6f}， Valid acc： {:.6f}， Valid loss： {:.6f}\".format(\n",
    "               epoch+1, num_epochs, \n",
    "               train_acc_, train_loss_,\n",
    "               valid_acc_, valid_loss_))\n",
    "        print('==========================================================================')\n",
    "\n",
    "    print(\"====== END ==========\")\n",
    "\n",
    "    return total_train_loss, total_valid_loss, total_train_accuracy, total_valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_loss, total_valid_loss, total_train_accuracy, total_valid_accuracy = training_loop(model, criterion, optimizer, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(total_train, total_valid, label):\n",
    "    plt.plot(range(num_epochs), total_train, 'b-', label=f'Training_{label}')\n",
    "    plt.plot(range(num_epochs), total_valid, 'g-', label=f'validation_{label}')\n",
    "    plt.title(f'Training & Validation {label}')\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel(f'{label}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(total_train_loss, total_valid_loss, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(total_train_accuracy, total_valid_accuracy, 'accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
